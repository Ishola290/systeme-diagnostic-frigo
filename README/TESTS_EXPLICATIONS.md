# ğŸ§ª RÃ”LE DES TESTS DANS LE SYSTÃˆME

## ğŸ“‹ Vue d'Ensemble

Le dossier `tests/` contient les **tests unitaires** qui vÃ©rifient que toutes les fonctionnalitÃ©s du systÃ¨me fonctionnent correctement.

```
tests/
â”œâ”€â”€ test_simple.py          â† Tests unitaires (validation, helpers, etc.)
â””â”€â”€ __init__.py             â† Marque le dossier comme package Python
```

---

## ğŸ¯ RÃ”LE PRINCIPAL

### âœ… Assurance QualitÃ©
Les tests s'assurent que :
- Les donnÃ©es sont validÃ©es correctement
- Les IDs diagnostics sont gÃ©nÃ©rÃ©s de maniÃ¨re unique
- Le score de santÃ© est calculÃ© correctement
- Les helpers fonctionnent comme prÃ©vu
- Aucune rÃ©gression entre versions

### ğŸ” DÃ©tection de Bugs
Les tests dÃ©tectent immÃ©diatement :
- âŒ Si validation Ã©choue
- âŒ Si donnÃ©es manquantes
- âŒ Si calcul score incorrect
- âŒ Si helpers ne fonctionnent pas

### ğŸ“Š Documentation Vivante
Les tests servent aussi de documentation :
- Montrent comment utiliser les fonctions
- Donnent des exemples concrets
- Expliquent les cas normaux ET limites

---

## ğŸ“ TESTS ACTUELS

### Test 1: `test_validation_donnees_valides()`

**Que teste-t-il ?**
```python
def test_validation_donnees_valides():
    """Test validation avec donnÃ©es valides"""
    donnees = {
        'TempÃ©rature': -18,
        'Pression_BP': 2.5,
        'Pression_HP': 12,
        'Courant': 5.5,
        'Tension': 220,
        'HumiditÃ©': 55,
        'DÃ©bit_air': 150,
        'Vibration': 2
    }
```

**VÃ©rifie :**
- âœ… DonnÃ©es valides sont acceptÃ©es
- âœ… Chaque valeur est convertie en float
- âœ… Tous les capteurs sont traitÃ©s

**UtilitÃ© :** S'assurer que le service de validation ne rejette pas les bonnes donnÃ©es

---

### Test 2: `test_validation_donnees_manquantes()`

**Que teste-t-il ?**
```python
def test_validation_donnees_manquantes():
    """Test validation avec donnÃ©es manquantes"""
    donnees = {
        'TempÃ©rature': -18,
        'Pression_BP': 2.5
        # Autres capteurs MANQUANTS!
    }
    
    with pytest.raises(ValueError, match="Champs manquants"):
        valider_donnees_capteurs(donnees)
```

**VÃ©rifie :**
- âœ… DonnÃ©es incomplÃ¨tes sont rejetÃ©es
- âœ… Un ValueError est levÃ©
- âœ… Message d'erreur appropriÃ©

**UtilitÃ© :** S'assurer que les donnÃ©es incomplÃ¨tes sont dÃ©tectÃ©es

---

### Test 3: `test_generer_diagnostic_id()`

**Que teste-t-il ?**
```python
def test_generer_diagnostic_id():
    """Test gÃ©nÃ©ration d'ID unique"""
    id1 = generer_diagnostic_id()
    id2 = generer_diagnostic_id()
    
    assert id1.startswith('DIAG_')
    assert id2.startswith('DIAG_')
    assert id1 != id2  # Chaque ID est unique!
```

**VÃ©rifie :**
- âœ… IDs commencent par 'DIAG_'
- âœ… Chaque ID est unique
- âœ… Format cohÃ©rent

**UtilitÃ© :** Garantir que chaque diagnostic a un identifiant unique

---

### Test 4: `test_score_sante()`

**Que teste-t-il ?**
```python
def test_score_sante():
    """Test calcul score de santÃ©"""
    donnees = {
        'TempÃ©rature': -18,      # Optimal
        'Pression_BP': 2.5,      # Optimal
        'Pression_HP': 12,       # Optimal
        # ... tous normaux
    }
    
    score = calculer_score_sante_global(donnees, Config.SEUILS)
    
    assert 0 <= score <= 100
    assert score > 80  # Score Ã©levÃ© = systÃ¨me sain
```

**VÃ©rifie :**
- âœ… Score est entre 0 et 100
- âœ… DonnÃ©es normales = score > 80
- âœ… Calcul cohÃ©rent

**UtilitÃ© :** S'assurer que le systÃ¨me sain a bon score

---

### Test 5: `test_score_sante_anomalie()`

**Que teste-t-il ?**
```python
def test_score_sante_anomalie():
    """Test score avec anomalie"""
    donnees = {
        'TempÃ©rature': 50,  # âš ï¸ ANOMALIE! (devrait Ãªtre -18)
        'Pression_BP': 2.5,
        # ... autres normaux
    }
    
    score = calculer_score_sante_global(donnees, Config.SEUILS)
    
    assert score < 80  # Score plus bas = anomalie dÃ©tectÃ©e
```

**VÃ©rifie :**
- âœ… Anomalies sont dÃ©tectÃ©es
- âœ… Score baisse avec anomalies
- âœ… Distinction normal vs anormal

**UtilitÃ© :** S'assurer que les pannes sont dÃ©tectÃ©es

---

## ğŸ”„ FLUX DE TEST

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DÃ©veloppeur modify le code     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  pytest test_*.py  â”‚  â† Lance tous les tests
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
        â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                             â”‚
        â†“                             â†“
    âœ… PASS                       âŒ FAIL
    â”‚                             â”‚
    â””â”€â†’ Code OK                   â””â”€â†’ BUG DÃ‰TECTÃ‰!
        Deploy possible               Fix required
```

---

## ğŸ’» COMMENT LANCER LES TESTS

### MÃ©thode 1: Pytest (RecommandÃ©)
```bash
# Activer environnement
venv\Scripts\Activate.ps1

# Lancer tous les tests
pytest tests/

# Lancer avec verbositÃ© (plus de dÃ©tails)
pytest tests/ -v

# Lancer un test spÃ©cifique
pytest tests/test_simple.py::test_validation_donnees_valides -v

# Lancer avec coverage (couverture de code)
pytest tests/ --cov=utils --cov=services
```

### MÃ©thode 2: Python Direct
```bash
# Lancer directement le fichier de test
python -m pytest tests/test_simple.py

# Ou
python tests/test_simple.py
```

### MÃ©thode 3: Depuis VS Code
```
1. Ouvrir test_simple.py
2. Clic droit â†’ "Run Tests"
3. Voir rÃ©sultats dans panneau "Test Explorer"
```

---

## ğŸ“Š RÃ‰SULTATS ATTENDUS

### SuccÃ¨s âœ…
```
tests/test_simple.py::test_validation_donnees_valides PASSED
tests/test_simple.py::test_validation_donnees_manquantes PASSED
tests/test_simple.py::test_generer_diagnostic_id PASSED
tests/test_simple.py::test_score_sante PASSED
tests/test_simple.py::test_score_sante_anomalie PASSED

====== 5 passed in 0.23s ======
```

### Ã‰chec âŒ
```
tests/test_simple.py::test_validation_donnees_valides FAILED
FAILED tests/test_simple.py::test_validation_donnees_valides
AssertionError: 0 != 1
```

---

## ğŸ—ï¸ ARCHITECTURE DES TESTS

### Structure Logique
```
test_simple.py
â”‚
â”œâ”€ Imports
â”‚  â””â”€ pytest, validation, helpers, config
â”‚
â”œâ”€ Test Suite 1: Validation
â”‚  â”œâ”€ test_validation_donnees_valides()      â† Cas normal
â”‚  â””â”€ test_validation_donnees_manquantes()   â† Cas erreur
â”‚
â”œâ”€ Test Suite 2: Helpers
â”‚  â””â”€ test_generer_diagnostic_id()           â† UnicitÃ©
â”‚
â””â”€ Test Suite 3: Calculs
   â”œâ”€ test_score_sante()                     â† Cas normal
   â””â”€ test_score_sante_anomalie()            â† DÃ©tection
```

### DÃ©pendances TestÃ©es
```
test_simple.py teste:
â”œâ”€ utils/validation.py
â”‚  â””â”€ valider_donnees_capteurs()
â”œâ”€ utils/helpers.py
â”‚  â”œâ”€ generer_diagnostic_id()
â”‚  â””â”€ calculer_score_sante_global()
â””â”€ config.py
   â””â”€ Config.SEUILS
```

---

## âœ¨ BONNES PRATIQUES

### 1ï¸âƒ£ Noms Clairs
```python
# âœ… BON
def test_validation_donnees_valides():
    """Test validation avec donnÃ©es valides"""

# âŒ MAUVAIS
def test_1():
    """Test"""
```

### 2ï¸âƒ£ Un Cas par Test
```python
# âœ… BON - Un test = un cas
def test_validation_donnees_valides():
    # Teste SEULEMENT les donnÃ©es valides

def test_validation_donnees_manquantes():
    # Teste SEULEMENT les donnÃ©es manquantes

# âŒ MAUVAIS - Plusieurs cas dans un test
def test_validation():
    # Test donnÃ©es valides
    # Test donnÃ©es manquantes
    # Test donnÃ©es invalides
    # ... Trop de logique!
```

### 3ï¸âƒ£ Setup/Teardown si NÃ©cessaire
```python
import pytest

@pytest.fixture
def donnees_test():
    """Setup: PrÃ©pare les donnÃ©es de test"""
    return {
        'TempÃ©rature': -18,
        'Pression_BP': 2.5,
        # ...
    }

def test_avec_fixture(donnees_test):
    """Utilise les donnÃ©es prÃ©-prÃ©parÃ©es"""
    result = valider_donnees_capteurs(donnees_test)
    assert result is not None
```

### 4ï¸âƒ£ Assertions Claires
```python
# âœ… BON - Clair et spÃ©cifique
assert score > 80, f"Score devrait Ãªtre > 80, got {score}"

# âŒ MAUVAIS - Trop gÃ©nÃ©ral
assert score
```

---

## ğŸš¨ QUAND LANCER LES TESTS

| Moment | Raison |
|--------|--------|
| ğŸ“ Avant commit | VÃ©rifier que code fonctionne |
| ğŸ”§ AprÃ¨s modification | S'assurer pas de rÃ©gression |
| ğŸ› Bug dÃ©tectÃ© | Reproduire et tester fix |
| ğŸ“¦ Avant deploy | Validation complÃ¨te |
| ğŸ”„ CI/CD | Tests automatiques |

---

## ğŸ“ˆ COUVERTURE DE CODE

**Couverture de code** = % de code testÃ©

```bash
# Voir la couverture
pytest tests/ --cov=utils --cov=services --cov-report=html

# Affiche dans HTML report quelles lignes ne sont pas testÃ©es
```

**Objectif:** â‰¥ 80% couverture

---

## ğŸ¯ TESTS FUTURS Ã€ AJOUTER

### Services IA
```python
def test_gemini_analyse():
    """Test service Gemini"""
    
def test_apprentissage_traiter():
    """Test service apprentissage"""
    
def test_telegram_send():
    """Test Telegram notification"""
```

### Simulateur
```python
def test_simulateur_pannes():
    """Test gÃ©nÃ©ration pannes"""
    
def test_simulateur_signature():
    """Test signature panne appliquÃ©e"""
```

### API
```python
def test_health_endpoint():
    """Test GET /health"""
    
def test_diagnostic_endpoint():
    """Test POST /webhook/diagnostic-frigo"""
```

### Integration
```python
def test_flux_complet():
    """Test workflow end-to-end"""
```

---

## ğŸ” EXEMPLE: AJOUTER UN TEST

### Pas 1: Identifier ce Ã  tester
```
Je veux tester le simulateur qui gÃ©nÃ¨re des pannes
```

### Pas 2: Ã‰crire le test
```python
def test_simulateur_panne():
    """Test gÃ©nÃ©ration d'une panne"""
    from simulateur import SimulateurCapteurs
    
    sim = SimulateurCapteurs(prob_panne=1.0)  # 100% chance
    diag = sim.generer_donnees_diagnostic()
    
    # Si prob=1.0, une panne DOIT Ãªtre gÃ©nÃ©rÃ©e
    assert sim.panne_active is not None
```

### Pas 3: Lancer et voir Ã©chouer
```bash
pytest tests/test_simple.py::test_simulateur_panne -v
# FAILED - attendu, on n'a pas encore le code!
```

### Pas 4: ImplÃ©menter le code
```python
# Dans simulateur.py
class SimulateurCapteurs:
    def generer_donnees_diagnostic(self):
        if random.random() < self.prob_panne:
            self.panne_active = random.choice(list(self.PANNES_SIGNATURES.keys()))
        # ...
```

### Pas 5: Relancer et vÃ©rifier le succÃ¨s
```bash
pytest tests/test_simple.py::test_simulateur_panne -v
# PASSED âœ…
```

---

## ğŸ“š RESSOURCES

- **Pytest Documentation** : https://docs.pytest.org/
- **Python unittest** : https://docs.python.org/3/library/unittest.html
- **Testing Best Practices** : https://realpython.com/python-testing/

---

## âœ… RÃ‰SUMÃ‰

| Aspect | DÃ©tail |
|--------|--------|
| **RÃ´le** | Assurer la qualitÃ© du code |
| **Lieu** | `tests/` dossier |
| **Fichier** | `test_simple.py` (5 tests) |
| **Framework** | Pytest |
| **FrÃ©quence** | Ã€ chaque modification |
| **Couverture** | Validation, Helpers, Calculs |
| **SuccÃ¨s** | 5/5 tests doivent passer |

---

## ğŸš€ COMMANDES RAPIDES

```bash
# Lancer tous les tests
pytest tests/ -v

# Lancer un test spÃ©cifique
pytest tests/test_simple.py::test_validation_donnees_valides -v

# Lancer avec couverture
pytest tests/ --cov --cov-report=html

# Lancer en watch mode (relance auto)
pytest-watch tests/

# Lancer avec rÃ©sultat verbeux
pytest tests/ -vv
```

---

**Les tests = Filet de sÃ©curitÃ© du systÃ¨me ! ğŸ›¡ï¸**

Sans tests â†’ Bugs se glissent facilement  
Avec tests â†’ QualitÃ© garantie âœ…
