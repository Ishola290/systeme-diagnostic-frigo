# ğŸš€ Processus de DÃ©ploiement AutomatisÃ© en Production

## Vue d'ensemble

Les Dockerfiles ont Ã©tÃ© **mis Ã  jour automatiquement** pour tÃ©lÃ©charger et inclure les modÃ¨les IA lors de la compilation. **Aucune Ã©tape manuelle n'est requise** â€” tout se fait pendant le build Docker.

---

## âœ… Dockerfiles Mis Ã  Jour

### 1. **Dockerfile** (Application principale - port 5000)
- âœ… Multi-stage build avec tÃ©lÃ©chargement automatique phi
- âœ… TÃ©lÃ©charge `phi-2` (5GB) lors du build Stage 1
- âœ… Inclut le modÃ¨le dans l'image finale
- â±ï¸ **Temps de build**: 15-25 min (premier build uniquement)
- âš¡ **Temps de dÃ©marrage**: ~2 secondes (modÃ¨le prÃ©-chargÃ©)

### 2. **gpt/Dockerfile** (Service IA - port 5002)
- âœ… Multi-stage build avec tÃ©lÃ©chargement automatique phi
- âœ… TÃ©lÃ©charge `phi-2` (5GB) lors du build Stage 1
- âœ… Inclut le modÃ¨le dans l'image finale
- â±ï¸ **Temps de build**: 15-25 min (premier build uniquement)
- âš¡ **Temps de dÃ©marrage**: ~2 secondes (modÃ¨le prÃ©-chargÃ©)

### 3. **chat/Dockerfile** (Service Chat - port 5001)
- âœ… Pas de modÃ¨les IA (utilise API distante)
- â±ï¸ **Temps de build**: 3-5 min
- âš¡ **Temps de dÃ©marrage**: ~1 seconde

---

## ğŸ”„ Processus de Compilation (CI/CD)

### **Phase 1: TÃ©lÃ©chargement des ModÃ¨les** (Stage 1)
```dockerfile
FROM python:3.11-slim as model-downloader
# ... install dependencies
COPY download_models.py .
RUN python download_models.py --model phi
# Output: /app/models/phi/ avec tous les fichiers
```
**Temps**: 10-15 min pour phi (5GB)
**RÃ©sultat**: ModÃ¨les tÃ©lÃ©chargÃ©s localement

### **Phase 2: Image Finale** (Stage 2)
```dockerfile
FROM python:3.11-slim
COPY --from=model-downloader /app/models /app/models
# ... copy app code
```
**Temps**: 5-10 min (installation dÃ©pendances, compilation)
**RÃ©sultat**: Image Docker complÃ¨te avec modÃ¨les inclus (~6.5GB)

### **Phase 3: Push vers Registry** (Render/Docker Hub)
**Temps**: 5-10 min (upload rÃ©seau)
**RÃ©sultat**: Image disponible sur la plateforme

---

## ğŸŒ DÃ©ploiement sur Render

### **Ã‰tape 1: CrÃ©er Web Service sur Render**

```bash
# URL: https://render.com/dashboard
# 1. New â†’ Web Service
# 2. Connect GitHub repository
# 3. Configuration:
```

| ParamÃ¨tre | Valeur |
|-----------|--------|
| **Name** | `frigo-app` |
| **Region** | `Frankfurt` |
| **Runtime** | `Docker` |
| **Build Command** | `docker build -f Dockerfile .` |
| **Start Command** | `python app.py` |
| **Instance Type** | `Standard (0.5 CPU, 512MB RAM)` |

### **Ã‰tape 2: Configurer les Variables d'Environnement**

```env
# AprÃ¨s crÃ©er le service, aller Ã  Environment
FLASK_ENV=production
PYTHONUNBUFFERED=1
CHAT_API_URL=https://frigo-chat.onrender.com
IA_SERVICE_URL=https://frigo-gpt.onrender.com
DATABASE_URL=postgresql://user:pass@host/db
```

### **Ã‰tape 3: DÃ©ployer**
- Le build commence automatiquement
- â±ï¸ **Premier build**: 20-30 min (modÃ¨les tÃ©lÃ©chargÃ©s)
- â±ï¸ **DÃ©ploiements suivants**: 5-10 min (cache Docker)
- âœ… Service en ligne quand tous les logs terminent

---

## ğŸ” Monitoring du Build

### **Console Render**
```
Build Log (Live):
  1. Fetching dependencies...
  2. Installing Python packages...
  3. Starting model download (phi-2)...
  4. Downloading from huggingface.co/microsoft/phi-2...
  5. âœ… Model phi downloaded successfully
  6. Installing app dependencies...
  7. Building final image...
  8. Image ready! Size: ~6.5GB
```

### **Signes d'Erreur Ã  Ã‰viter**
```
âŒ "Timeout downloading model" 
   â†’ Render a limitÃ© le temps de build (~45 min)
   â†’ Solution: Augmenter l'instance type

âŒ "Disk space full"
   â†’ Image finale trop grande
   â†’ Solution: Utiliser instance avec plus de stockage

âŒ "Out of memory"
   â†’ Build a manquÃ© de RAM
   â†’ Solution: RedÃ©ployer (Render retry automatiquement)
```

---

## ğŸ“‹ Architecture Multi-Service

### **Service 1: App (Render)**
```
frigo-app.onrender.com
â”œâ”€â”€ Port: 5000 (public via HTTPS)
â”œâ”€â”€ ENV CHAT_API_URL=https://frigo-chat.onrender.com
â”œâ”€â”€ ENV IA_SERVICE_URL=https://frigo-gpt.onrender.com
â””â”€â”€ ModÃ¨le: phi-2 (5GB, inclus dans image)
```

### **Service 2: Chat (Render)**
```
frigo-chat.onrender.com
â”œâ”€â”€ Port: 5001 (public via HTTPS)
â””â”€â”€ Pas de modÃ¨les (lÃ©ger, 500MB)
```

### **Service 3: IA (Render)**
```
frigo-gpt.onrender.com
â”œâ”€â”€ Port: 5002 (public via HTTPS)
â”œâ”€â”€ ENV IA_MODEL=phi
â””â”€â”€ ModÃ¨le: phi-2 (5GB, inclus dans image)
```

---

## ğŸ”— Auto-Sync URLs (Fonctionnel)

### **DÃ©tection Automatique**
```python
# Dans app.py et app_ia.py
chat_url = os.getenv('CHAT_API_URL')  # PrioritÃ© 1: Render env vars

if not chat_url:
    try:
        chat_url = socket.gethostbyname('chat')  # PrioritÃ© 2: Docker DNS
    except:
        chat_url = 'http://localhost:5001'  # Fallback 3: Local dev
```

### **RÃ©sultat**
- âœ… En local (Python): `http://localhost:5001`
- âœ… En local (Docker Compose): `http://chat:5001` (DNS Docker)
- âœ… En production (Render): `https://frigo-chat.onrender.com` (env var)

---

## ğŸš€ DÃ©ploiement Complet (Checklist)

### **Avant le DÃ©ploiement**

- [ ] Git push complÃ©tÃ©: `git push origin main`
- [ ] Dockerfiles validÃ©s (v3 avec multi-stage)
- [ ] requirements.txt Ã  jour dans racine et gpt/
- [ ] download_models.py en place (racine + gpt/)
- [ ] Variables d'env testÃ©es localement

### **Pendant le DÃ©ploiement**

#### **1. CrÃ©er frigo-app**
```
1. Connect GitHub
2. Build: docker build -f Dockerfile .
3. Env: CHAT_API_URL, IA_SERVICE_URL
4. Deploy
5. Attendre 20-30 min (premier build)
6. VÃ©rifier: curl https://frigo-app.onrender.com/health
```

#### **2. CrÃ©er frigo-chat**
```
1. Connect GitHub
2. Build: docker build -f chat/Dockerfile .
3. Env: MAIN_APP_URL=https://frigo-app.onrender.com
4. Deploy
5. Attendre 5-10 min
6. VÃ©rifier: curl https://frigo-chat.onrender.com/health
```

#### **3. CrÃ©er frigo-gpt**
```
1. Connect GitHub
2. Build: docker build -f gpt/Dockerfile .
3. Env: MAIN_APP_URL=https://frigo-app.onrender.com
4. Deploy
5. Attendre 20-30 min (premier build avec modÃ¨le)
6. VÃ©rifier: curl https://frigo-gpt.onrender.com/health
```

### **AprÃ¨s le DÃ©ploiement**

- [ ] Tous les services en ligne
- [ ] Health checks passent (GET /health)
- [ ] Tester `/api/simulator/start` en production
- [ ] Tester `/api/finetune/start` en production
- [ ] VÃ©rifier logs pour erreurs

---

## ğŸ“Š Timing RÃ©fÃ©rence

| Phase | Temps | Notes |
|-------|-------|-------|
| **Git push** | 2-5 min | Tous les fichiers ~50MB |
| **Build app (Stage 1)** | 10-15 min | TÃ©lÃ©charge phi-2 (5GB) |
| **Build app (Stage 2)** | 5-10 min | Installation deps |
| **Build gpt (Stage 1)** | 10-15 min | TÃ©lÃ©charge phi-2 (5GB) |
| **Build gpt (Stage 2)** | 5-10 min | Installation deps |
| **Build chat** | 3-5 min | Pas de modÃ¨les |
| **Total production** | 50-70 min | Premier dÃ©ploiement complet |
| **DÃ©ploiements suivants** | 15-25 min | Cache Docker utilisÃ© |

---

## âš¡ Optimisations Post-Build

### **Cache Docker Layer**
```
Build 1: 20-30 min (download stage)
Build 2: 5-10 min (skip download, use cache)
Build 3: 5-10 min (skip download, use cache)
...
```
**Ã‰conomie**: 60% du temps sur redÃ©ploiements

### **Connexion Ã  PostgreSQL (Optionnel)**
```env
# Render â†’ Postgres
DATABASE_URL=postgresql://user:password@dpg-xxxxx.onrender.com:5432/dbname
```

### **Monitoring Render Dashboard**
- Logs temps rÃ©el
- MÃ©triques CPU/RAM
- RedÃ©ployment automatique sur crash

---

## ğŸ› Troubleshooting

### **Le build est trop long (> 45 min)**
```
Render a un timeout de ~45 min
â†’ Augmenter instance type (Standard â†’ Premium)
â†’ Ou rÃ©duire modÃ¨le (phi â†’ gpt2)
```

### **ModÃ¨le ne se tÃ©lÃ©charge pas**
```
Error: "No space left on device"
â†’ Instance n'a pas assez de disque
â†’ Solution: Premium instance (50GB)
```

### **Service ne dÃ©marre pas aprÃ¨s build**
```
Error: "ModuleNotFoundError: No module named 'torch'"
â†’ requirements.txt incomplet
â†’ VÃ©rifier: pip freeze > requirements.txt
```

### **API retourne 502 Bad Gateway**
```
Service crash probable
â†’ VÃ©rifier logs Render
â†’ RedÃ©ployer manuellement
```

---

## ğŸ“ RÃ©sumÃ©

âœ… **AutomatisÃ©**: ModÃ¨les tÃ©lÃ©chargÃ©s lors du build Docker
âœ… **Multi-stage**: RÃ©duit taille finale, cache les dÃ©pendances
âœ… **Production-ready**: HTTPS, health checks, env vars
âœ… **Scalable**: Render gÃ¨re auto load-balancing
âœ… **ZÃ©ro-config**: URLs auto-dÃ©tectÃ©es entre services

**Prochaine Ã©tape**: CrÃ©er les 3 Web Services sur Render et dÃ©ployer! ğŸš€
