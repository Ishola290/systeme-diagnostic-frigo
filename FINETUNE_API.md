# ðŸ”¬ Fine-Tuning API - RÃ©entraÃ®nement Production

## ðŸ“ Vue d'ensemble

Vous pouvez maintenant **rÃ©entraÃ®ner les modÃ¨les IA Ã  la demande** directement depuis l'API!

```
Service: gpt/app_ia.py
Port: 5002
Endpoint: POST /api/finetune/start
Description: Lance le fine-tuning asynchrone avec vos donnÃ©es
RÃ©ponse: ImmÃ©diate (202 Accepted)
```

---

## ðŸŽ¯ UtilitÃ©

Le fine-tuning permet d'adapter les modÃ¨les IA Ã  **votre domaine spÃ©cifique** (frigorifique):

```
Avant (ModÃ¨le GÃ©nÃ©raliste):
  Q: "Frigo fait bruit fort"
  A: "C'est normal, tous les frigos font du bruit"
  âŒ RÃ©ponse gÃ©nÃ©rale, pas adaptÃ©

AprÃ¨s (Fine-tuning Frigo):
  Q: "Frigo fait bruit fort"  
  A: "VÃ©rifiez le compresseur, le ventilateur, 
      et l'accumulation de givre"
  âœ… RÃ©ponse spÃ©cialisÃ©e pour frigorifique!
```

---

## ðŸš€ Utilisation

### 1ï¸âƒ£ Obtenir les Infos (DÃ©couvrez les Options)

```bash
curl http://localhost:5002/api/finetune/info

# RÃ©ponse:
{
  "available": true,
  "supported_models": ["phi", "phi2", "mistral", "neural"],
  "supported_formats": ["csv", "jsonl"],
  "endpoints": {...}
}
```

### 2ï¸âƒ£ Lancer le Fine-Tuning (Simple)

```bash
curl -X POST http://localhost:5002/api/finetune/start \
  -H "Content-Type: application/json" \
  -d '{
    "model": "phi",
    "dataset_url": "data/frigo_training.csv"
  }'

# RÃ©ponse: 202 Accepted
{
  "status": "started",
  "job_id": "ft_20240115_103045_abc123",
  "message": "Fine-tuning lancÃ© pour phi",
  "config": {
    "model": "phi",
    "dataset": "data/frigo_training.csv",
    "epochs": 3,
    "batch_size": 4,
    "learning_rate": 2e-5
  }
}
```

### 3ï¸âƒ£ Lancer Fine-Tuning (PersonnalisÃ©)

```bash
# Configuration complÃ¨te
curl -X POST http://localhost:5002/api/finetune/start \
  -H "Content-Type: application/json" \
  -d '{
    "model": "mistral",
    "dataset_url": "https://example.com/frigo_data.jsonl",
    "epochs": 5,
    "batch_size": 2,
    "learning_rate": 1e-5
  }'

# RÃ©ponse:
{
  "job_id": "ft_20240115_103045_xyz789",
  "status": "started",
  "message": "Fine-tuning lancÃ©"
}
```

### 4ï¸âƒ£ VÃ©rifier le Statut

```bash
curl http://localhost:5002/api/finetune/status/ft_20240115_103045_abc123

# RÃ©ponse:
{
  "job_id": "ft_20240115_103045_abc123",
  "status": "completed",
  "progress": 1.0,
  "model_path": "models/phi-finetuned-20240115_103045/"
}
```

### 5ï¸âƒ£ Lister les ModÃ¨les Fine-TunÃ©s

```bash
curl http://localhost:5002/api/finetune/models

# RÃ©ponse:
{
  "models": [
    {
      "name": "phi-finetuned-20240115_103045",
      "base_model": "phi",
      "created": "2024-01-15T10:30:45",
      "size_mb": 2540,
      "latest": true,
      "path": "models/phi-finetuned-20240115_103045"
    },
    {
      "name": "mistral-finetuned-20240114_150000",
      "base_model": "mistral",
      "created": "2024-01-14T15:00:00",
      "size_mb": 6500,
      "path": "models/mistral-finetuned-20240114_150000"
    }
  ],
  "total": 2
}
```

---

## ðŸ“‹ ParamÃ¨tres

| ParamÃ¨tre | Type | DÃ©faut | Plage | Description |
|-----------|------|--------|-------|-------------|
| `model` | string | - | phi, mistral, neural, gpt2 | ModÃ¨le Ã  rÃ©entraÃ®ner |
| `dataset_url` | string | - | - | Chemin/URL du dataset |
| `epochs` | int | 3 | 1-20 | Nombre de passes sur les donnÃ©es |
| `batch_size` | int | 4 | 1-16 | Taille des batches |
| `learning_rate` | float | 2e-5 | - | Taux d'apprentissage |

---

## ðŸ“Š Format des DonnÃ©es

### Format CSV

```csv
text
"Frigo trÃ¨s froid, compresseur fait bruit"
"Fuite d'eau sous le frigo"
"Thermostat dÃ©faillant, tempÃ©rature inconstante"
...
```

**Fichier:** `data/frigo_training.csv`

```bash
# CrÃ©er et charger
curl -X POST http://localhost:5002/api/finetune/start \
  -d '{
    "model": "phi",
    "dataset_url": "data/frigo_training.csv"
  }'
```

### Format JSONL

```jsonl
{"text": "Frigo trÃ¨s froid, compresseur fait bruit"}
{"text": "Fuite d'eau sous le frigo"}
{"text": "Thermostat dÃ©faillant, tempÃ©rature inconstante"}
```

**Fichier:** `data/frigo_training.jsonl`

```bash
# Charger depuis JSONL
curl -X POST http://localhost:5002/api/finetune/start \
  -d '{
    "model": "mistral",
    "dataset_url": "data/frigo_training.jsonl"
  }'
```

---

## ðŸ’» Exemples de Code

### Python

```python
import requests
import json

# 1. Info
response = requests.get('http://localhost:5002/api/finetune/info')
print(response.json())

# 2. Lancer fine-tuning
response = requests.post(
    'http://localhost:5002/api/finetune/start',
    json={
        'model': 'phi',
        'dataset_url': 'data/frigo_training.csv',
        'epochs': 3,
        'batch_size': 4
    }
)
job_id = response.json()['job_id']
print(f"Fine-tuning lancÃ©: {job_id}")

# 3. VÃ©rifier statut
response = requests.get(f'http://localhost:5002/api/finetune/status/{job_id}')
status = response.json()
print(f"Status: {status['status']}, Progress: {status['progress']*100}%")

# 4. Lister modÃ¨les
response = requests.get('http://localhost:5002/api/finetune/models')
models = response.json()['models']
for model in models:
    print(f"- {model['name']} ({model['size_mb']}MB)")
```

### JavaScript/Fetch

```javascript
// 1. Lancer fine-tuning
fetch('http://localhost:5002/api/finetune/start', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    model: 'phi',
    dataset_url: 'data/frigo_training.csv',
    epochs: 3
  })
})
.then(r => r.json())
.then(data => {
  console.log('Job ID:', data.job_id);
  
  // 2. VÃ©rifier statut
  setInterval(() => {
    fetch(`http://localhost:5002/api/finetune/status/${data.job_id}`)
      .then(r => r.json())
      .then(status => console.log('Status:', status.status))
  }, 5000)
})

// 3. Lister modÃ¨les
fetch('http://localhost:5002/api/finetune/models')
  .then(r => r.json())
  .then(data => console.log('ModÃ¨les:', data.models))
```

### PowerShell

```powershell
# 1. Lancer fine-tuning
$body = @{
    model = "phi"
    dataset_url = "data/frigo_training.csv"
    epochs = 3
} | ConvertTo-Json

$response = Invoke-WebRequest -Uri "http://localhost:5002/api/finetune/start" `
  -Method POST `
  -Headers @{'Content-Type' = 'application/json'} `
  -Body $body

$jobId = ($response.Content | ConvertFrom-Json).job_id
Write-Host "Job ID: $jobId"

# 2. VÃ©rifier statut
$status = Invoke-WebRequest -Uri "http://localhost:5002/api/finetune/status/$jobId"
$status.Content | ConvertFrom-Json | Select-Object status, progress
```

---

## ðŸŒ Production (Render)

Une fois dÃ©ployÃ©, vous pouvez rÃ©entraÃ®ner en production:

```bash
# Depuis votre machine
curl -X POST https://frigo-gpt.onrender.com/api/finetune/start \
  -H "Content-Type: application/json" \
  -d '{
    "model": "phi",
    "dataset_url": "https://example.com/frigo_data.csv",
    "epochs": 5,
    "batch_size": 2
  }'

# Job ID retournÃ©
# Fine-tuning lance en background sur Render
# Logs disponibles: Render Dashboard â†’ Logs
```

---

## ðŸ“ˆ Cas d'Usage

### 1. Test Fine-Tuning Local

```bash
# Petite donnÃ©e de test (10 exemples)
curl -X POST http://localhost:5002/api/finetune/start \
  -d '{
    "model": "gpt2",
    "dataset_url": "data/test_frigo.csv",
    "epochs": 1,
    "batch_size": 1
  }'

# DurÃ©e: ~2 minutes
# Valider que le processus fonctionne
```

### 2. Fine-Tuning Complet

```bash
# Dataset complet (1000+ exemples)
curl -X POST http://localhost:5002/api/finetune/start \
  -d '{
    "model": "phi",
    "dataset_url": "data/frigo_complet.csv",
    "epochs": 3,
    "batch_size": 4,
    "learning_rate": 2e-5
  }'

# DurÃ©e: ~30-60 minutes (dÃ©pend GPU)
# ModÃ¨le hautement spÃ©cialisÃ© aprÃ¨s
```

### 3. Production - RÃ©entraÃ®nement Mensuel

```bash
# En production: rÃ©entraÃ®ner avec donnÃ©es du mois
curl -X POST https://frigo-gpt.onrender.com/api/finetune/start \
  -d '{
    "model": "phi",
    "dataset_url": "https://s3.amazonaws.com/data/frigo_nov2024.csv",
    "epochs": 5
  }'

# S'exÃ©cute en background
# Nouveau modÃ¨le prÃªt aprÃ¨s ~1 heure
# Logs en temps rÃ©el disponibles
```

### 4. Comparaison ModÃ¨les

```bash
# Fine-tuner plusieurs modÃ¨les
models = ["gpt2", "phi", "mistral"]

for model in models:
    curl -X POST http://localhost:5002/api/finetune/start \
      -d "{\"model\": \"$model\", \"dataset_url\": \"data/test.csv\"}"

# Comparer les modÃ¨les fine-tunÃ©s
# SÃ©lectionner le meilleur pour production
```

---

## âœ… Workflow RecommandÃ©

### Phase 1: PrÃ©parer les DonnÃ©es

```bash
# 1. Collecter des cas rÃ©els
#    - Diagnostics effectuÃ©s
#    - ProblÃ¨mes rencontrÃ©s
#    - Solutions appliquÃ©es

# 2. Formater en CSV/JSONL
cat > data/frigo_training.csv << EOF
text
"Bruit compresseur â†’ VÃ©rifier huile, accumulateur"
"Froid insuffisant â†’ VÃ©rifier thermostat, capteur"
...
EOF

# 3. Valider format
wc -l data/frigo_training.csv  # Doit avoir 100+ lignes
```

### Phase 2: Test Fine-Tuning

```bash
# Tester avec petit dataset
curl -X POST http://localhost:5002/api/finetune/start \
  -d '{
    "model": "gpt2",
    "dataset_url": "data/frigo_training.csv",
    "epochs": 1,
    "batch_size": 1
  }'

# Attendre ~2 min
# VÃ©rifier pas d'erreurs
```

### Phase 3: Production Fine-Tuning

```bash
# Fine-tuner le modÃ¨le complet
curl -X POST http://localhost:5002/api/finetune/start \
  -d '{
    "model": "phi",
    "dataset_url": "data/frigo_training.csv",
    "epochs": 5,
    "batch_size": 4
  }'

# Attendre ~1 heure
# Nouveau modÃ¨le: models/phi-finetuned-20240115_103045/
```

### Phase 4: Utiliser Nouveau ModÃ¨le

```python
# Dans app_ia.py ou autre service:
import os

# Option 1: Auto-dÃ©tection (modÃ¨le le plus rÃ©cent)
fine_tuned_models = os.listdir('models')
latest = sorted([m for m in fine_tuned_models if 'finetuned' in m])[-1]
model_path = f'models/{latest}'

# Option 2: SpÃ©cifier explicitement
os.environ['IA_MODEL_PATH'] = 'models/phi-finetuned-20240115_103045'
```

---

## âš¡ DurÃ©e Fine-Tuning

| ModÃ¨le | DonnÃ©es | GPU | CPU | Epochs |
|--------|---------|-----|-----|--------|
| gpt2 | 100 | 1-2 min | 5-10 min | 1 |
| phi | 100 | 3-5 min | 15-30 min | 3 |
| mistral | 100 | 5-10 min | 30-60 min | 3 |
| phi | 1000 | 10-20 min | 60-120 min | 3 |
| phi | 10000 | 60-120 min | 300+ min | 5 |

**Note:** DurÃ©e dÃ©pend de hardware disponible

---

## ðŸŽ¯ Meilleure Pratique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Collecter donnÃ©es rÃ©elles             â”‚
â”‚    (Cas d'utilisation de production)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. Formatter CSV/JSONL                   â”‚
â”‚    (VÃ©rifier qualitÃ© donnÃ©es)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. Fine-tuner sur model petit (gpt2)     â”‚
â”‚    (Test et validation)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. Fine-tuner sur modÃ¨le large (phi)     â”‚
â”‚    (Production final)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 5. Ã‰valuer performances                  â”‚
â”‚    (Comparer avant/aprÃ¨s)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 6. DÃ©ployer en production                â”‚
â”‚    (Utiliser nouveau modÃ¨le)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ‰ RÃ©sumÃ©

Vous avez maintenant **API complÃ¨te pour rÃ©entraÃ®ner Ã  la demande**:

```bash
# Une requÃªte pour adapter vos modÃ¨les:
curl -X POST http://localhost:5002/api/finetune/start \
  -d '{
    "model": "phi",
    "dataset_url": "data/frigo_training.csv",
    "epochs": 5
  }'

# Et le modÃ¨le s'adapte Ã  votre domaine! ðŸš€
```

**Prochaines versions:**
- âœ… Monitoring du fine-tuning
- âœ… Utilisation automatique du modÃ¨le fine-tunÃ©
- âœ… Stockage des modÃ¨les sur cloud (S3, etc.)
- âœ… Pipeline rÃ©entraÃ®nement automatique

---

Voir `SIMULATOR_TRIGGER_API.md` pour endpoint simulateur ðŸŽ¯
