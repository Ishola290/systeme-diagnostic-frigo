"""
API Flask - Service IA Local
Endpoints pour traiter les messages et alertes
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import logging
import sys
import os
import requests
from datetime import datetime
from pathlib import Path

# Import du service IA
from ia_service import get_ia_service

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ia_service.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# Initialisation Flask
app = Flask(__name__)
CORS(app)

# Configuration
app.config['JSON_SORT_KEYS'] = False

# URLs des services
CHAT_SERVICE_URL = os.environ.get('CHAT_API_URL', 'http://localhost:5001')
TELEGRAM_SERVICE_URL = os.environ.get('MAIN_API_URL', 'http://localhost:5000')  # Pour appel Telegram via app.py

# Service IA
ia_service = None
_initialized = False

def init_ia_service():
    """Initialiser le service IA au d√©marrage"""
    global ia_service, _initialized
    if not _initialized:
        # Lire le mod√®le depuis env var IA_MODEL
        # Si non sp√©cifi√©, auto-s√©lection selon ressources
        model_choice = os.environ.get('IA_MODEL')
        
        if model_choice:
            logger.info(f"üì¶ Mod√®le IA depuis env IA_MODEL: {model_choice}")
        else:
            logger.info(f"üì¶ Auto-s√©lection du mod√®le IA selon ressources disponibles")
        
        ia_service = get_ia_service(model_choice)
        _initialized = True
        logger.info("‚úÖ Service IA initialis√©")

# Hook pour initialiser avant la premi√®re requ√™te (compatible Flask 3.0)
@app.before_request
def ensure_initialized():
    """Assurer l'initialisation du service IA"""
    global _initialized
    if not _initialized:
        init_ia_service()

# ==================== ENDPOINTS ====================

@app.route('/health', methods=['GET'])
def health():
    """Health check du service"""
    return jsonify({
        'status': 'ok',
        'service': 'IA Local',
        'timestamp': datetime.now().isoformat()
    }), 200

@app.route('/api/chat/message', methods=['POST'])
def process_chat_message():
    """
    Traiter un message du chat
    Fluide + Logging d√©taill√© + Gestion erreurs gracieuse
    
    Request:
        {
            "message": "Message utilisateur",
            "user_id": "user123",
            "user_name": "admin",
            "source": "websocket|rest"
        }
    
    Response:
        {
            "success": true,
            "response": "R√©ponse du service IA",
            "intent": "diagnostic",
            "processing_time_ms": 1234,
            "model": "phi",
            "timestamp": "..."
        }
    """
    import time
    start_time = time.time()
    
    try:
        data = request.get_json()
        message = data.get('message', '').strip()
        user_id = data.get('user_id', 'anonymous')
        user_name = data.get('user_name', 'Utilisateur')
        source = data.get('source', 'rest')
        
        if not message:
            logger.warning(f"‚ö†Ô∏è Message vide re√ßu de {user_id}")
            return jsonify({
                'success': False,
                'error': 'Message vide'
            }), 400
        
        logger.info(f"üí¨ [{source}] Message de {user_name} ({user_id}): {message[:50]}...")
        
        # Traiter le message via le service IA
        if not ia_service:
            logger.error("‚ùå Service IA non initialis√©")
            return jsonify({
                'success': False,
                'error': 'Service IA non disponible'
            }), 503
        
        result = ia_service.process_chat_message(message, user_id)
        
        # Ajouter temps de traitement
        processing_time_ms = int((time.time() - start_time) * 1000)
        result['processing_time_ms'] = processing_time_ms
        
        logger.info(f"‚úÖ R√©ponse g√©n√©r√©e en {processing_time_ms}ms pour {user_name}")
        
        return jsonify(result), 200 if result['success'] else 500
    
    except Exception as e:
        logger.error(f"‚ùå ERREUR traitement message: {e}", exc_info=True)
        return jsonify({
            'success': False,
            'error': f'Erreur traitement: {str(e)}'
        }), 500

@app.route('/api/alerts/process', methods=['POST'])
def process_alert():
    """
    Traiter une alerte depuis app.py
    Enrichir ‚Üí Envoyer au Chat Web ‚Üí Envoyer √† Telegram
    
    Request:
        {
            "type": "error",
            "title": "Titre alerte",
            "message": "Message d'alerte",
            "severity": "critical",
            "diagnostic_id": "..."
        }
    
    Response:
        {
            "success": true,
            "alert": {
                "...original fields...",
                "processed": true,
                "severity_score": 3.5,
                "suggested_solutions": [...]
            }
        }
    """
    try:
        alert_data = request.get_json()
        logger.info(f"üö® Alerte re√ßue: {alert_data.get('title', 'N/A')}")
        
        # 1Ô∏è‚É£ Traiter l'alerte avec le service IA
        processed_alert = ia_service.process_alert(alert_data)
        
        # 2Ô∏è‚É£ Envoyer au Chat Web
        try:
            chat_payload = {
                'type': alert_data.get('type', 'error'),
                'title': alert_data.get('title', 'Alerte'),
                'message': processed_alert.get('analysis', alert_data.get('message', '')),
                'diagnostic_id': alert_data.get('diagnostic_id'),
                'severity': alert_data.get('severity', 'medium')
            }
            
            chat_response = requests.post(
                f"{CHAT_SERVICE_URL}/api/receive-alert",
                json=chat_payload,
                timeout=5
            )
            
            if chat_response.status_code == 201:
                logger.info(f"‚úÖ Alerte envoy√©e au Chat Web")
            else:
                logger.warning(f"‚ö†Ô∏è Chat Web retourn√© {chat_response.status_code}")
        except Exception as e:
            logger.error(f"‚ùå Erreur envoi Chat Web: {e}")
        
        # 3Ô∏è‚É£ Envoyer notification √† Telegram via app.py
        try:
            telegram_payload = {
                'message': f"üö® {alert_data.get('title', 'Alerte')}\n\n{processed_alert.get('analysis', alert_data.get('message', ''))}"
            }
            
            telegram_response = requests.post(
                f"{TELEGRAM_SERVICE_URL}/api/telegram/notify",
                json=telegram_payload,
                timeout=5
            )
            
            if telegram_response.status_code == 200:
                logger.info(f"‚úÖ Notification Telegram envoy√©e")
            else:
                logger.warning(f"‚ö†Ô∏è Telegram retourn√© {telegram_response.status_code}")
        except Exception as e:
            logger.error(f"‚ùå Erreur envoi Telegram: {e}")
        
        return jsonify({
            'success': True,
            'alert': processed_alert,
            'chat_notified': True,
            'telegram_notified': True
        }), 200
    
    except Exception as e:
        logger.error(f"‚ùå Erreur traitement alerte: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/knowledge/add', methods=['POST'])
def add_knowledge():
    """
    Ajouter une entr√©e √† la base de connaissances
    
    Request:
        {
            "topic": "Cl√©",
            "content": "Contenu"
        }
    
    Response:
        {
            "success": true,
            "message": "Entr√©e ajout√©e"
        }
    """
    try:
        data = request.get_json()
        topic = data.get('topic', '').strip()
        content = data.get('content', '').strip()
        
        if not topic or not content:
            return jsonify({'error': 'Topic et content requis'}), 400
        
        ia_service.add_to_knowledge_base(topic, content)
        
        logger.info(f"‚úÖ Entr√©e KB ajout√©e: {topic}")
        return jsonify({
            'success': True,
            'message': f'Entr√©e "{topic}" ajout√©e'
        }), 201
    
    except Exception as e:
        logger.error(f"‚ùå Erreur ajout KB: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/stats', methods=['GET'])
def get_stats():
    """
    Obtenir les statistiques du service
    
    Response:
        {
            "model": "phi",
            "messages_processed": 123,
            "knowledge_base_size": 45,
            "uptime": "..."
        }
    """
    try:
        stats = ia_service.get_stats()
        return jsonify(stats), 200
    except Exception as e:
        logger.error(f"‚ùå Erreur r√©cup√©ration stats: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/models', methods=['GET'])
def get_models():
    """
    Lister les mod√®les disponibles
    
    Response:
        {
            "available_models": {
                "mistral": "mistral-7b-instruct",
                ...
            },
            "current_model": "phi"
        }
    """
    from ia_service import IAConfig
    config = IAConfig()
    return jsonify({
        'available_models': config.MODEL_OPTIONS,
        'current_model': ia_service.model_name
    }), 200

@app.route('/api/diagnostic/analyze', methods=['POST'])
def analyze_diagnostic():
    """
    Analyser les donn√©es de diagnostic et proposer des solutions
    
    Request:
        {
            "symptoms": ["temp√©rature √©lev√©e", "bruit"],
            "measurements": {
                "temperature": 35,
                "pressure_hp": 15,
                ...
            }
        }
    
    Response:
        {
            "success": true,
            "diagnosis": "...",
            "solutions": [...],
            "confidence": 0.85
        }
    """
    try:
        data = request.get_json()
        symptoms = data.get('symptoms', [])
        measurements = data.get('measurements', {})
        
        logger.info(f"üîç Diagnostic: {symptoms}")
        
        # Construire un message pour le service IA
        diagnostic_msg = f"Diagnostic: {', '.join(symptoms)}"
        
        # Traiter via le service IA
        result = ia_service.process_chat_message(diagnostic_msg, 'diagnostic_system')
        
        return jsonify({
            'success': True,
            'diagnosis': result['response'],
            'symptoms': symptoms,
            'intent': result['intent']
        }), 200
    
    except Exception as e:
        logger.error(f"‚ùå Erreur diagnostic: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/learn', methods=['POST'])
def learn():
    """
    Permettre au syst√®me d'apprendre de nouveaux cas
    
    Request:
        {
            "case": "Description du cas",
            "solution": "Solution trouv√©e",
            "confidence": 0.9
        }
    
    Response:
        {
            "success": true,
            "message": "Cas d'apprentissage enregistr√©"
        }
    """
    try:
        data = request.get_json()
        case = data.get('case', '').strip()
        solution = data.get('solution', '').strip()
        confidence = data.get('confidence', 0.8)
        
        if not case or not solution:
            return jsonify({'error': 'Case et solution requis'}), 400
        
        # Sauvegarder comme entr√©e KB
        ia_service.add_to_knowledge_base(
            f"learned_{case[:20]}",
            {
                'case': case,
                'solution': solution,
                'confidence': confidence,
                'learned_at': datetime.now().isoformat()
            }
        )
        
        logger.info(f"üìö Apprentissage: {case[:30]}...")
        return jsonify({
            'success': True,
            'message': 'Cas d\'apprentissage enregistr√©'
        }), 201
    
    except Exception as e:
        logger.error(f"‚ùå Erreur apprentissage: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/finetune/info', methods=['GET'])
def finetune_info():
    """
    üìä Endpoint pour obtenir les infos du fine-tuning
    
    Utilisation:
        GET http://localhost:5002/api/finetune/info
    
    R√©ponse:
        {
            "available": true,
            "description": "Fine-tuning sur mesure des mod√®les...",
            "supported_models": [...],
            "supported_formats": ["csv", "jsonl"],
            "examples": {...}
        }
    """
    return jsonify({
        'available': True,
        'description': 'Fine-tuning sur mesure pour domaine frigorifique',
        'supported_models': ['phi', 'phi2', 'mistral', 'neural'],
        'supported_formats': ['csv', 'jsonl'],
        'endpoints': {
            'start': {
                'method': 'POST',
                'path': '/api/finetune/start',
                'description': 'D√©marre le fine-tuning asynchrone',
                'params': {
                    'model': 'Mod√®le √† fine-tuner (phi, mistral, etc)',
                    'dataset_url': 'URL ou chemin du dataset',
                    'epochs': 'Nombre epochs (default: 3)',
                    'batch_size': 'Batch size (default: 4)',
                    'learning_rate': 'Learning rate (default: 2e-5)'
                }
            },
            'status': {
                'method': 'GET',
                'path': '/api/finetune/status/{job_id}',
                'description': 'Obtenir le statut du fine-tuning'
            },
            'models': {
                'method': 'GET',
                'path': '/api/finetune/models',
                'description': 'Lister les mod√®les fine-tun√©s'
            }
        },
        'examples': {
            'quick_start': {
                'description': 'Fine-tune phi sur donn√©es locales',
                'curl': 'curl -X POST http://localhost:5002/api/finetune/start -H "Content-Type: application/json" -d \'{"model": "phi", "dataset_url": "data/frigo_training.csv"}\'',
                'python': 'requests.post("http://localhost:5002/api/finetune/start", json={"model": "phi", "dataset_url": "data/frigo_training.csv"})'
            },
            'full_config': {
                'description': 'Fine-tune mistral avec config compl√®te',
                'curl': 'curl -X POST http://localhost:5002/api/finetune/start -H "Content-Type: application/json" -d \'{"model": "mistral", "dataset_url": "https://example.com/data.jsonl", "epochs": 5, "batch_size": 2, "learning_rate": 1e-5}\'',
                'python': 'requests.post("http://localhost:5002/api/finetune/start", json={"model": "mistral", "dataset_url": "https://example.com/data.jsonl", "epochs": 5, "batch_size": 2})'
            }
        }
    }), 200


@app.route('/api/finetune/start', methods=['POST'])
def start_finetune():
    """
    üéØ Endpoint pour d√©marrer le fine-tuning en production
    
    D√©clenche le r√©entra√Ænement asynchrone d'un mod√®le sur des donn√©es frigo-sp√©cifiques
    
    Utilisation:
        POST http://localhost:5002/api/finetune/start
        Content-Type: application/json
        
        {
            "model": "phi",
            "dataset_url": "data/frigo_training.csv",
            "epochs": 3,
            "batch_size": 4,
            "learning_rate": 2e-5
        }
    
    R√©ponse:
        {
            "status": "started",
            "job_id": "ft_20240115_103045_12345",
            "message": "Fine-tuning lanc√©",
            "config": {...}
        }
    """
    try:
        import subprocess
        import threading
        import uuid
        from datetime import datetime as dt
        
        # Param√®tres par d√©faut
        params = request.get_json() or {}
        model = params.get('model', 'phi')
        dataset_url = params.get('dataset_url')
        epochs = params.get('epochs', 3)
        batch_size = params.get('batch_size', 4)
        learning_rate = params.get('learning_rate', 2e-5)
        
        # Validation
        if not dataset_url:
            logger.warning("‚ö†Ô∏è  Pas de dataset_url fourni")
            return jsonify({'error': 'dataset_url requis'}), 400
        
        if model not in ['phi', 'phi2', 'mistral', 'neural', 'gpt2']:
            return jsonify({'error': f'Mod√®le non support√©: {model}'}), 400
        
        if not (1 <= epochs <= 20):
            return jsonify({'error': 'epochs doit √™tre entre 1 et 20'}), 400
        
        if not (1 <= batch_size <= 16):
            return jsonify({'error': 'batch_size doit √™tre entre 1 et 16'}), 400
        
        # G√©n√©rer job ID unique
        timestamp = dt.now().strftime('%Y%m%d_%H%M%S')
        job_id = f"ft_{timestamp}_{str(uuid.uuid4())[:8]}"
        
        # Pr√©parer la commande fine-tuning
        cmd = [
            'python',
            'fine_tune.py',
            '--model', model,
            '--data', dataset_url,
            '--epochs', str(epochs),
            '--batch-size', str(batch_size),
            '--learning-rate', str(learning_rate),
            '--job-id', job_id
        ]
        
        logger.info(f"üöÄ D√©marrage fine-tuning [JOB: {job_id}]")
        logger.info(f"   Mod√®le: {model}")
        logger.info(f"   Dataset: {dataset_url}")
        logger.info(f"   Config: epochs={epochs}, batch_size={batch_size}, lr={learning_rate}")
        
        # Lancer le fine-tuning en arri√®re-plan (thread daemon)
        def run_finetune():
            try:
                # Changer vers le r√©pertoire parent (o√π fine_tune.py existe)
                import os
                original_dir = os.getcwd()
                os.chdir('..')
                
                subprocess.run(cmd, check=True, capture_output=True, text=True)
                
                os.chdir(original_dir)
                logger.info(f"‚úÖ Fine-tuning termin√© [JOB: {job_id}]")
                logger.info(f"   Mod√®le fine-tun√© sauvegard√©: models/{model}-finetuned-{timestamp}/")
            
            except subprocess.CalledProcessError as e:
                logger.error(f"‚ùå Fine-tuning √©chou√© [JOB: {job_id}]: {e.stderr}")
            except Exception as e:
                logger.error(f"‚ùå Exception fine-tuning [JOB: {job_id}]: {e}")
        
        # Lancer dans un thread s√©par√© (non-bloquant)
        thread = threading.Thread(target=run_finetune, daemon=True)
        thread.start()
        
        return jsonify({
            'status': 'started',
            'job_id': job_id,
            'message': f'Fine-tuning lanc√© pour {model}',
            'config': {
                'model': model,
                'dataset': dataset_url,
                'epochs': epochs,
                'batch_size': batch_size,
                'learning_rate': learning_rate
            },
            'timestamp': dt.now().isoformat()
        }), 202
    
    except Exception as e:
        logger.error(f"‚ùå Erreur d√©marrage fine-tuning: {e}")
        return jsonify({
            'error': str(e),
            'message': 'Erreur lors du d√©marrage du fine-tuning'
        }), 500


@app.route('/api/finetune/status/<job_id>', methods=['GET'])
def finetune_status(job_id):
    """
    üìä V√©rifier le statut du fine-tuning
    
    Utilisation:
        GET http://localhost:5002/api/finetune/status/ft_20240115_103045_abc123
    
    R√©ponse:
        {
            "job_id": "ft_...",
            "status": "running|completed|failed",
            "progress": 0.65,
            "eta_seconds": 180,
            "model_path": "models/phi-finetuned-20240115_103045/"
        }
    """
    try:
        import os
        from pathlib import Path
        
        # Chercher le mod√®le fine-tun√© associ√©
        models_dir = Path('../models')
        
        # Format du dossier: {model}-finetuned-{timestamp}
        timestamp = job_id.split('_')[1:3]  # Extraire timestamp du job_id
        timestamp_str = '_'.join(timestamp) if len(timestamp) >= 2 else None
        
        status = 'unknown'
        model_path = None
        progress = 0.0
        
        if timestamp_str and models_dir.exists():
            # Chercher un dossier correspondant
            for model_dir in models_dir.glob('*-finetuned-*'):
                if timestamp_str in str(model_dir):
                    status = 'completed'
                    model_path = str(model_dir)
                    progress = 1.0
                    break
        
        return jsonify({
            'job_id': job_id,
            'status': status,
            'progress': progress,
            'model_path': model_path,
            'timestamp': datetime.now().isoformat()
        }), 200
    
    except Exception as e:
        logger.error(f"‚ùå Erreur statut fine-tuning: {e}")
        return jsonify({
            'error': str(e),
            'job_id': job_id,
            'status': 'unknown'
        }), 500


@app.route('/api/finetune/models', methods=['GET'])
def list_finetuned_models():
    """
    üìö Lister les mod√®les fine-tun√©s disponibles
    
    Utilisation:
        GET http://localhost:5002/api/finetune/models
    
    R√©ponse:
        {
            "models": [
                {
                    "name": "phi-finetuned-20240115_103045",
                    "base_model": "phi",
                    "created": "2024-01-15T10:30:45",
                    "size_mb": 2540,
                    "latest": true
                },
                ...
            ]
        }
    """
    try:
        from pathlib import Path
        import os
        
        models_dir = Path('../models')
        finetuned_models = []
        
        if models_dir.exists():
            for model_dir in models_dir.glob('*-finetuned-*'):
                if model_dir.is_dir():
                    # Extraire infos
                    model_name = model_dir.name
                    base_model = model_name.split('-finetuned-')[0]
                    
                    # Taille du dossier
                    size_mb = sum(
                        os.path.getsize(os.path.join(dirpath, filename))
                        for dirpath, _, filenames in os.walk(model_dir)
                        for filename in filenames
                    ) / (1024 * 1024)
                    
                    # Date de cr√©ation
                    created = datetime.fromtimestamp(model_dir.stat().st_mtime).isoformat()
                    
                    finetuned_models.append({
                        'name': model_name,
                        'base_model': base_model,
                        'created': created,
                        'size_mb': round(size_mb, 2),
                        'path': str(model_dir)
                    })
        
        # Trier par date d√©croissante
        finetuned_models.sort(key=lambda x: x['created'], reverse=True)
        
        # Marquer le plus r√©cent
        if finetuned_models:
            finetuned_models[0]['latest'] = True
        
        return jsonify({
            'models': finetuned_models,
            'total': len(finetuned_models),
            'timestamp': datetime.now().isoformat()
        }), 200
    
    except Exception as e:
        logger.error(f"‚ùå Erreur listing mod√®les: {e}")
        return jsonify({
            'error': str(e),
            'models': []
        }), 500


@app.errorhandler(404)
def not_found(error):
    """Endpoint non trouv√©"""
    return jsonify({'error': 'Endpoint non trouv√©'}), 404

@app.errorhandler(500)
def internal_error(error):
    """Erreur interne"""
    logger.error(f"‚ùå Erreur interne: {error}")
    return jsonify({'error': 'Erreur interne du serveur'}), 500

# ==================== MAIN ====================

if __name__ == '__main__':
    logger.info("üöÄ D√©marrage du service IA local")
    logger.info("üìù Endpoints disponibles:")
    logger.info("   POST /api/chat/message - Traiter message chat")
    logger.info("   POST /api/alerts/process - Traiter alerte")
    logger.info("   POST /api/knowledge/add - Ajouter √† KB")
    logger.info("   GET  /api/stats - Statistiques")
    logger.info("   GET  /api/models - Mod√®les disponibles")
    logger.info("   POST /api/diagnostic/analyze - Analyser diagnostic")
    logger.info("   POST /api/learn - Apprentissage")
    logger.info("   üî¨ FINE-TUNING:")
    logger.info("   GET  /api/finetune/info - Info fine-tuning")
    logger.info("   POST /api/finetune/start - D√©marrer fine-tuning")
    logger.info("   GET  /api/finetune/status/{job_id} - Statut job")
    logger.info("   GET  /api/finetune/models - Lister mod√®les")
    logger.info("   GET  /health - Health check")
    
    app.run(host='0.0.0.0', port=5002, debug=False)
